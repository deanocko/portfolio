<!DOCTYPE html>
<html lang="en" data-wf-page="646399e0a1bace702c764b54" data-wf-site="63dbf0d7a8c0be3a7f72bfa2" data-theme="light">
	<head>
		<!-- Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-51KB5CWB9T"></script>
		<script>
			window.dataLayer = window.dataLayer || [];
			function gtag() {
				dataLayer.push(arguments);
			}
			gtag("js", new Date());
			gtag("config", "G-51KB5CWB9T");
		</script>

		<!-- Basic Meta Tags -->
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<title>AAVI</title>

		<!-- Social Media Meta Tags -->
		<meta property="og:title" content="AAVI" />
		<meta property="twitter:title" content="AAVI" />

		<!-- Stylesheets -->
		<link href="../css/variables.css" rel="stylesheet" type="text/css" />
		<link href="../css/normalize.css" rel="stylesheet" type="text/css" />
		<link href="../css/webflow.css" rel="stylesheet" type="text/css" />
		<link href="../css/myPortfolio.css" rel="stylesheet" type="text/css" />

		<!-- Fonts -->
		<link href="https://fonts.googleapis.com" rel="preconnect" />
		<link href="https://fonts.gstatic.com" rel="preconnect" crossorigin />
		<script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js"></script>
		<script>
			WebFont.load({
				google: {
					families: [
						"Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic",
						"Manrope:200,300,regular,500,600,700,800",
					],
				},
			});
		</script>

		<!-- Favicon -->
		<link href="../images/favicon.jpg" rel="shortcut icon" type="image/x-icon" />
		<link href="../images/webclip.png" rel="apple-touch-icon" />
	</head>

	<body class="body">
		<!-- Navigation Bar -->
		<nav
			class="navigation w-nav"
			data-collapse="medium"
			data-animation="default"
			data-duration="400"
			data-easing="ease"
			data-easing2="ease"
			role="banner"
		>
			<div class="navigation-items">
				<a href="../index.html" class="logo-link w-nav-brand">
					<div class="title-logo">dean<span class="heading">ocko</span></div>
				</a>
				<div class="navigation-wrap">
					<nav role="navigation" class="navigation-items w-nav-menu">
						<a href="../index.html#Resume" class="navigation-item w-nav-link">Resume</a>
						<a href="../index.html#Capstone" class="navigation-item w-nav-link">Capstone</a>
						<a href="../index.html#Projects" class="navigation-item w-nav-link">Projects</a>
						<a href="../index.html#Contact" class="navigation-item w-nav-link">Contact</a>
						<button id="darkModeToggle" class="dark-mode-toggle" aria-label="Toggle dark mode">
							<svg class="theme-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
								<path
									class="moon"
									d="M12 3c-4.97 0-9 4.03-9 9s4.03 9 9 9 9-4.03 9-9c0-.46-.04-.92-.1-1.36-.98 1.37-2.58 2.26-4.4 2.26-3.03 0-5.5-2.47-5.5-5.5 0-1.82.89-3.42 2.26-4.4-.44-.06-.9-.1-1.36-.1z"
								/>
								<path
									class="sun"
									d="M12 7c-2.76 0-5 2.24-5 5s2.24 5 5 5 5-2.24 5-5-2.24-5-5-5zM2 13h2c.55 0 1-.45 1-1s-.45-1-1-1H2c-.55 0-1 .45-1 1s.45 1 1 1zm18 0h2c.55 0 1-.45 1-1s-.45-1-1-1h-2c-.55 0-1 .45-1 1s.45 1 1 1zM11 2v2c0 .55.45 1 1 1s1-.45 1-1V2c0-.55-.45-1-1-1s-1 .45-1 1zm0 18v2c0 .55.45 1 1 1s1-.45 1-1v-2c0-.55-.45-1-1-1s-1 .45-1 1zM5.99 4.58c-.39-.39-1.03-.39-1.41 0-.39.39-.39 1.03 0 1.41l1.06 1.06c.39.39 1.03.39 1.41 0s.39-1.03 0-1.41L5.99 4.58zm12.37 12.37c-.39-.39-1.03-.39-1.41 0-.39.39-.39 1.03 0 1.41l1.06 1.06c.39.39 1.03.39 1.41 0 .39-.39.39-1.03 0-1.41l-1.06-1.06zm1.06-10.96c.39-.39.39-1.03 0-1.41-.39-.39-1.03-.39-1.41 0l-1.06 1.06c-.39.39-.39 1.03 0 1.41s1.03.39 1.41 0l1.06-1.06zM7.05 18.36c.39-.39.39-1.03 0-1.41-.39-.39-1.03-.39-1.41 0l-1.06 1.06c-.39.39-.39 1.03 0 1.41s1.03.39 1.41 0l1.06-1.06z"
								/>
							</svg>
						</button>
					</nav>
					<div class="menu-button w-nav-button">
						<img width="22" src="../images/menu-icon_1menu-icon.png" alt="Menu" class="menu-icon" />
					</div>
				</div>
			</div>
		</nav>

		<!-- Main Content -->
		<main class="container">
			<div class="content-wrapper">
				<section class="section">
					<div class="project-container">
						<!-- Project Header -->
						<div class="title-section">
							<h1 class="heading-jumbo">Automated Aircraft Visual Inspection (AAVI)</h1>
							<p class="paragraph-light">My 2024 UTS Capstone Project on Computer Vision & Deep Learning</p>
						</div>

						<!-- Project Media -->
						<div class="video-container">
							<img
								src="../images/AAVI.webp"
								loading="lazy"
								alt="Automated Aircraft Visual Inspection System"
								style="
									width: 100%;
									height: auto;
									display: block;
									border-radius: 6px;
									margin: 0 6px;
									max-width: calc(100% - 12px);
								"
							/>
						</div>

						<!-- Project Details -->
						<div class="project-content">
							<!-- Summary -->
							<article class="project-bubble summary">
								<h2 class="body subheading mobile">Summary</h2>
								<ul class="paragraph-light mobile left-align">
									<li>Identified a research gap for automated aircraft defect detection systems</li>
									<li>
										Devised an automated aircraft visual inspection (AAVI) system that uses a lightweight CNN
										model to defect a range of aircraft defects in real-time
									</li>
									<li>
										Compiled a novel, public aircraft defect dataset with Dent, Crack and Missing Fastener
										classes
									</li>
									<li>
										Finetuned the YOLO-NAS-L model on the dataset as a proof of concept and achieved the
										current best results in the literature for automated aircraft defect detection
									</li>
									<li>
										AAVI selected among the top 5% of UTS Engineering capstone projects and presented at the
										2024 UTS Capstone Showcase - Shortlisted for the UTS IEEE award
									</li>
									<li>
										“Aircraft Visual Inspection; A Benchmark of Machine Learning Models” accepted for poster
										publication at the 2024 Australasian Conference on Robotics and Automation (ACRA)
									</li>
								</ul>
							</article>

							<!-- Read My Full Thesis Button -->
							<div class="explore-projects-button-div explore-projects-button-container">
								<a
									href="https://drive.google.com/file/d/102C3h1ac4q1Q0e1WXN69H3h-jqYFA6d3/view?usp=sharing"
									target="_blank"
									class="button w-button"
								>
									Read My Full Capstone Report
									<svg class="document-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
										<path
											d="M14 2H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h12c1.1 0 2-.9 2-2V8l-6-6zm4 18H6V4h7v5h5v11z"
										/>
										<path d="M9 13h6v2H9zm0 3h6v2H9z" />
									</svg>
								</a>
							</div>

							<div class="spacer"></div>

							<!-- Read Associated Publication Button -->
							<div class="explore-projects-button-div explore-projects-button-container">
								<a
									href="https://drive.google.com/file/d/1-4HdObKZvkQ4QyhMToGsj_rvAgGj2oQk/view?usp=share_link"
									target="_blank"
									class="button w-button"
								>
									Read Associated Publication
									<svg class="document-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
										<path
											d="M14 2H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h12c1.1 0 2-.9 2-2V8l-6-6zm4 18H6V4h7v5h5v11z"
										/>
										<path d="M9 13h6v2H9zm0 3h6v2H9z" />
									</svg>
								</a>
							</div>
							

							<!-- Project Overview -->
							<article class="project-bubble overview">
								<h2 class="body subheading mobile">Project Overview</h2>
								<p class="paragraph-light mobile">
									The Automated Aircraft Visual Inspection (AAVI) project represents a significant advancement
									in automated defect detection for aircraft maintenance. Using state-of-the-art YOLO-NAS (You
									Only Look Once - Neural Architecture Search) technology, this system achieves unprecedented
									accuracy in identifying various types of aircraft surface defects.<br /><br />

									This innovative solution addresses the critical need for efficient and reliable aircraft
									inspection processes, potentially reducing inspection time while maintaining or improving
									accuracy.<br /><br />

									Our approach involved several key steps including dataset preparation with diverse aircraft
									surface defect images, implementation of YOLO-NAS architecture for defect detection, model
									training with optimised hyperparameters, extensive testing and validation on real-world
									scenarios, and thorough performance analysis and optimisation.
								</p>
							</article>

							<article class="project-bubble methodology">
								<h1 class="body heading">Methodology</h1>
								<p class="paragraph-light mobile">
									The AAVI system combines hardware and software innovations to create a streamlined approach to
									aircraft defect inspection. Its design centers around two components:
									<br /><br />

									<!-- Image Container -->
									<div class="image-container">
										<img
											src="../images/AAVIsystemDiagram.webp"
											loading="lazy"
											alt="Project Title"
											style="
												width: 70%;
												height: auto;
												display: block;
												border-radius: 6px;
												margin: 0 6px;
												max-width: calc(100% - 12px);
											"
										/>
										<div class="caption">AAVI System Diagram</div>
									</div>

									<strong>1. Data Acquisition Network (DAN)</strong><br />
									The DAN employs a hybrid solution of drones and stationary
									cameras to ensure thorough visual coverage of aircraft, even in challenging inspection areas.
									Unmanned Aerial Vehicles (UAVs), such as DJI Matrice drones, scan the external and upper
									surfaces, while stationary cameras focus on intricate areas like undercarriages and landing
									gear. Images captured by the DAN are streamed in real-time for processing.
									<br /><br />

									<strong>2. Data Analysis and Sharing Hub (DASH) </strong><br> 
									Captured image data is routed to DASH, which uses DCNN
									models for defect detection. The first model performs Defect Detection in Real-Time (DDRT),
									designed for speed and edge-device efficiency, such as GPU-enabled platforms. This is critical
									for providing actionable insights within the 20–40 minute window between flights. The second
									model, for Defect Detection Post-Hoc (DDPH), prioritises high precision and recall, ensuring
									even subtle defects not flagged by the real-time system are identified before the aircraft
									Post-Hoc (DDPH), prioritises high precision and recall, ensuring even subtle defects not
									flagged by the real-time system are identified before the aircraft resumes operations.
									<br /><br />

									The methodology is bolstered by image-labeling mechanisms, allowing models to retrain and
									adapt over time. Insights from failed inspections can propagate across systems worldwide,
									continually refining the process. This adaptive design makes the system resilient and
									future-proof, with potential applications in edge hardware scenarios, regulations adherence,
									and evolving model architectures.
								</p>
								<!-- Image Container -->
								<div class="image-container">
									<img
										src="../images/AAVI Flowchart.png"
										loading="lazy"
										alt="Project Title"
										style="
											width: 100%;
											height: auto;
											display: block;
											border-radius: 6px;
											margin: 0 6px;
											max-width: calc(100% - 12px);
										"
									/>
									<div class="caption">AAVI System Process Flowchart.</div>
								</div>

								<br /><br />

								<h2 class="body subheading mobile">Dataset Creation and Composition</h2>
								<p class="paragraph-light mobile">
									To facilitate the training and evaluation of the AAVI models, a comprehensive dataset was
									curated from six publicly available datasets, consisting of 4,492 images. After refinement,
									this dataset focused on three defect classes—cracks, dents, and missing fasteners. A key
									element of this work involved intensive cleaning, where duplicate images, augmented data, and
									unsuitable images (e.g., video-game captures and misannotated photos) were filtered out.
									<br /><br />

									Class distributions revealed imbalances—missing fasteners were the most common (1,720
									instances), while dents were underrepresented (915 instances). These limitations influenced
									model performance but were mitigated through carefully designed augmentations.
									<br /><br />

									To improve robustness against variability in real-world inspections, augmentations were
									applied, such as flipping, cropping, mosaics, and exposure adjustments. This expanded the
									dataset to over 5,800 training images, allowing the model to better generalise across diverse
									inspection scenarios.
									<br />

									<!-- Image Container -->
									<div class="image-container">
										<img
											src="../images/datasetExample.webp"
											loading="lazy"
											alt="Project Title"
											style="
												width: 100%;
												height: auto;
												display: block;
												border-radius: 6px;
												margin: 0 6px;
												max-width: calc(100% - 12px);
											"
										/>
									</div>
									<br />

									Finally, the dataset was split into 78% training, 15% validation, and 7% testing subsets.
									While slightly under the conventional 30% validation/testing split, this division maximised
									the model’s exposure to valuable training data while retaining enough test cases for reliable
									evaluations.
									<br /><br />

									<!-- Image Container -->
									<div class="image-container">
										<img
											src="../images/datasetHealth.png"
											loading="lazy"
											alt="Project Title"
											style="
												width: 100%;
												height: auto;
												display: block;
												border-radius: 6px;
												margin: 0 6px;
												max-width: calc(100% - 12px);
											"
										/>
										<div class="caption">Class breakdown of the compiled dataset.</div>
									</div>

					
								</p>
							</article>

							<!-- Access the Compiled Dataset Button -->
							<div class="explore-projects-button-div explore-projects-button-container">
								<a
									href="https://app.roboflow.com/dean-ockenden/aircraft-defects-sycqk/3"
									target="_blank"
									class="button w-button"
								>
									Access The Compiled Dataset
									<svg class="document-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
										<path
											d="M14 2H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h12c1.1 0 2-.9 2-2V8l-6-6zm4 18H6V4h7v5h5v11z"
										/>
										<path d="M9 13h6v2H9zm0 3h6v2H9z" />
									</svg>
								</a>
							</div>

							<!-- Results -->
							<article class="project-bubble results">
								<h2 class="body subheading mobile">Results</h2>
								<p class="paragraph-light mobile">
									The evaluation focused on both model performance and practical feasibility in real-time
									environments. The YOLO-NAS-L model was fine-tuned on the dataset and compared against
									competing architectures in the YOLO family (YOLOv5-L, YOLOv8-L, YOLOv9-e).
									<br />
									
									<table>
										<caption>Performance comparison of YOLO family models finetuned on the novel dataset.</caption> <!-- Optional: Title for the table -->
										<thead>
											<tr> <!-- Heading Row  -->
												<th>Metric</th>
												<th>v5-L</th>
												<th>v8-L</th>
												<th>NAS-L (47%)</th>
												<th>v9-e</th>									
											</tr>
										</thead>
										<tbody>
											<tr>
												<td>Recall(50)</td> <!-- Metric  -->
												<td>0.759</td> <!-- v5  -->
												<td>0.784</td> <!-- v8  -->
												<td><strong>0.8167</strong></td> <!-- NAS -->
												<td>0779</td> <!-- v9 -->											
											</tr>
											<tr>
												<td>Precision(50)</td> <!-- Metric  -->
												<td>0.877</td> <!-- v5  -->
												<td>0.880</td> <!-- v8  -->
												<td>0.8382</td> <!-- NAS -->
												<td><strong>0.881</strong></td> <!-- v9 -->
												
											</tr>
											<tr>
												<td>mAP(50)</td> <!-- Metric  -->
												<td>0.825</td> <!-- v5  -->
												<td><strong>0.848</strong></td> <!-- v8  -->
												<td>0.8467</td> <!-- NAS -->
												<td>0.840</td> <!-- v9 -->
											</tr>
											<tr>
												<td>F2(50)</td> <!-- Metric  -->
												<td>0.78</td> <!-- v5  -->
												<td>0.8014</td> <!-- v8  -->
												<td><strong>0.8209</strong></td> <!-- NAS -->
												<td>0.8053</td> <!-- v9 -->
											</tr>
											<tr> <!-- FPS -->
												<td>FPS (FP16)</td> <!-- Metric  -->
												<td>131.06</td> <!-- v5  -->
												<td><strong>136.71</strong></td> <!-- v8  -->
												<td>98.52</td> <!-- NAS -->
												<td>73.45</td> <!-- v9 -->
											</tr>
										</tbody>
									</table>
									<br />

									The fine-tuned YOLO-NAS-L model demonstrated strong results, achieving an mAP@50 of 84.67%. Using and optimised
									confidence threshold of 47% it achieved an F2-score of 82.09%, with precision at 83.82% and
									recall at 81.67%. Importantly, the system achieved a
									comparable rate of false negatives (33%) to human inspectors while significantly reducing inspection times.
									<br /><br />

									Latency tests demonstrated the model’s viability for real-time deployment. On an NVIDIA T4
									GPU, inference latency was 10.15 ms or 98.52 frames per second using FP16
									quantization.
									<br /><br />

		

									<!-- Image Container -->
									<div class="image-container">
										<img
											src="../images/confusionMatrix.png"
											loading="lazy"
											alt="Project Title"
											style="
												width: 80%;
												height: auto;
												display: block;
												border-radius: 6px;
												margin: 0 6px;
												max-width: calc(100% - 12px);
											"
										/>
										<div class="caption">Confusion Matrix for the Finetuned YOLO-NAS model optimised at 47% confidence.</div>
									</div>
									<br />

									<strong>Class-Specific Insights:</strong> 
									<br />
									• Dents: High detection accuracy (~92%) and the lowest false negative rate (21%). <br />
									• Cracks: Lowest performance due to class imbalances and dataset variability; 47% false
									negatives. <br />
									• Missing Fasteners: Intermediate performance with 32% false negatives. <br />
									<br />
									Limitations remain in scenarios with non-standard lighting, weather conditions, and rare
									defect types. Addressing these will improve generalisability and reliability.
								</p>
							</article>

							<!-- Inference Examples -->
							<article class="project-bubble inference-examples">
								<h2 class="body subheading mobile centre-text">Inference Examples</h2>
								<!-- Image Container -->
								<div class="image-container">
									<img
										src="../images/Inference Examples.webp"
										loading="lazy"
										alt="Project Title"
										style="
											width: 100%;
											height: auto;
											display: block;
											border-radius: 6px;
											margin: 0 6px;
											max-width: calc(100% - 12px);
										"
									/>
								</div>
							</article>

							<!-- Potential Improvements -->
							<article class="project-bubble potential-improvements">
								<h2 class="body subheading mobile">Potential Improvements</h2>
								<p class="paragraph-light mobile">
									<strong>1. Dataset Refinement</strong><br /> Increasing diversity in images by incorporating
									weather conditions, angles, and lighting scenarios. Labeling defect severity can add practical
									value for prioritizing maintenance actions. <br /><br />

									<strong>2. Model Innovation</strong><br /> Expanding the DDPH component with advanced NAS
									techniques, such as the Clonal Selection Algorithm (CSA), tailored for high-recall,
									high-precision tasks. <br /><br />

									<strong>3. Hardware Optimisation</strong><br /> Validating DDRT for deployment on compact platforms
									like NVIDIA Jetson Xavier, ensuring real-time, edge-based inspections using industry-standard
									drones.
								</p>
							</article>

							<!-- Acknowledgements -->
							<article class="project-bubble acknowledgements">
								<h2 class="body subheading mobile">Acknowledgements</h2>
								<p class="paragraph-light mobile">
									I would like to express huge thanks to my project supervisor, <strong>Mason Brown</strong>,
									who helped guide me through the entirety of this project offering sage advice and patiently
									fielding questions.
								</p>
							</article>

							<!-- Technologies and Skills -->
							<article class="project-bubble technologies-and-skills">
								<h2 class="body subheading mobile centre-text">Core Technologies and Skills</h2>
								<div class="tech-section">
									<div class="tech-category">
										<h3 class="centre-text">Technologies and Tools</h3>
										<div class="tech-items">
											<div class="tech-item">YOLO-NAS</div>
											<div class="tech-item">Python</div>
											<div class="tech-item">PyTorch</div>
											<div class="tech-item">Roboflow</div>
											<div class="tech-item">Supergradients</div>
											<div class="tech-item">Ultralytics</div>
											<div class="tech-item">Git</div>
											<div class="tech-item">Overleaf</div>
										</div>
									</div>
									<div class="tech-category">
										<h3 class="centre-text">AI & ML</h3>
										<div class="tech-items">
											<div class="tech-item">Deep Learning</div>
											<div class="tech-item">Computer Vision</div>
											<div class="tech-item">Object Detection</div>
											<div class="tech-item">Dataset Creation</div>
											<div class="tech-item">Dataset Augmentation</div>
											<div class="tech-item">Model Finetuning</div>
											<div class="tech-item">Model Evaluation</div>
											<div class="tech-item">Evaluation Metrics</div>
										</div>
									</div>
								</div>
							</article>
						</div>
					</div>
				</section>

				<!-- Contact Section -->
				<section id="Contact" class="contact-section">
					<!-- Explore My Other Projects Button -->
					<div class="explore-projects-button-div explore-projects-button-container">
						<a href="../index.html#Projects" class="button w-button">Explore My Other Projects</a>
					</div>
					<div class="or-spacer">
						<p class="paragraph-light mobile centre-text">or</p>
					</div>
					<div class="div-block-9">
						<h1 class="heading-1">Get in touch</h1>

						<!-- Resume Button -->
						<div class="button-container">
							<a
								href="https://docs.google.com/document/d/146dTgOORDiDoFQXuJC-75Ako6Wubpat55qfPZamrU5A/edit?usp=sharing"
								target="_blank"
								class="button w-button"
							>
								View My Resume
								<svg class="document-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
									<path
										d="M14 2H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h12c1.1 0 2-.9 2-2V8l-6-6zm4 18H6V4h7v5h5v11z"
									/>
									<path d="M9 13h6v2H9zm0 3h6v2H9z" />
								</svg>
							</a>
						</div>

						<!-- LinkedIn Button -->
						<div class="button-container">
							<a href="https://www.linkedin.com/in/deanockenden/" target="_blank" class="button w-button"
								>Connect on LinkedIn
								<svg class="linkedin-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
									<path
										d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z"
									/>
								</svg>
							</a>
						</div>

						<!-- Email Button -->
						<div class="button-container">
							<a href="mailto:dean.ockenden@gmail.com" class="button w-button"
								>Send Me an Email
								<svg class="email-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
									<path
										d="M20 4H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 4l-8 5-8-5V6l8 5 8-5v2z"
									/>
								</svg>
							</a>
						</div>
					</div>
				</section>
			</div>
		</main>

		<!-- Scripts -->
		<script
			src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=63dbf0d7a8c0be3a7f72bfa2"
			integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
			crossorigin="anonymous"
		></script>
		<script src="../js/webflow.js"></script>
		<script src="../js/darkMode.js"></script>
	</body>
</html>
